{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyvd0ZFX7rgv"
   },
   "outputs": [],
   "source": [
    "!pip -qq install torchutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plgu4Q8g7ho8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# Для чтения изображений с диска\n",
    "from torchvision import io # input/output\n",
    "import torchutils as tu\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models import vgg16, VGG16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCzZXmRb7wh4",
    "outputId": "1197a2cb-d1ba-434a-f1b0-a40486087954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPV1ylNxGXcQ",
    "outputId": "15e37edd-d00a-4888-a3a6-adc3a17db299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOvYWSEGG3Dd"
   },
   "outputs": [],
   "source": [
    "zip_file_path = '/content/drive/MyDrive/Colab Notebooks/archive.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjUejd2eHA9k",
    "outputId": "5983442e-341a-4aea-beeb-d6c9a26b240e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Разархивирование завершено!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Укажите путь к вашему архиву\n",
    "extract_path = '/content/dataset/'  # Путь для разархивированных файлов\n",
    "\n",
    "# Создайте директорию, если она не существует\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# Разархивируйте файл\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Разархивирование завершено!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcfJoy4C65jj"
   },
   "outputs": [],
   "source": [
    "trnsfrms = T.Compose(\n",
    "    [\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7OM095zEXAML"
   },
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(\n",
    "    '/content/dataset/train',\n",
    "    transform=trnsfrms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-QJ-d-hYMni"
   },
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = random_split(dataset, lengths=(.7, .3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ev9z9tv3M1yO"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wtqAHD5lR1QZ",
    "outputId": "c898540f-3149-4da7-a437-974571cfcd41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = io.read_image('/content/dataset/test/altar/220.jpg')/255\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTdxeIo3TO9y"
   },
   "outputs": [],
   "source": [
    "class MyResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # подгружаем модель\n",
    "        self.model = vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "        # заменяем слой\n",
    "        self.model.fc = nn.Linear(2048, 10)\n",
    "        # замораживаем слои\n",
    "        for i in self.model.parameters():\n",
    "            i.requires_grad = False\n",
    "        # размораживаем только последний, который будем обучать\n",
    "        self.model.fc.weight.requires_grad = True\n",
    "        self.model.fc.bias.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = MyResNet()\n",
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Va3cwgKSTZoT"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "SNxZaCoqTcwl",
    "outputId": "5ec1b493-f725-4651-d3ef-b7119f16723d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================\n",
      "Layer                                               Kernel              Output         Params          FLOPs\n",
      "============================================================================================================\n",
      "0_model.Conv2d_conv1                               [3, 64, 7, 7]    [4, 64, 32, 32]       9,408   38,535,168\n",
      "1_model.BatchNorm2d_bn1                                     [64]    [4, 64, 32, 32]         128    1,048,576\n",
      "2_model.ReLU_relu                                              -    [4, 64, 32, 32]           0            0\n",
      "3_model.MaxPool2d_maxpool                                      -    [4, 64, 16, 16]           0            0\n",
      "4_model.layer1.0.Conv2d_conv1                     [64, 64, 1, 1]    [4, 64, 16, 16]       4,096    4,194,304\n",
      "5_model.layer1.0.BatchNorm2d_bn1                            [64]    [4, 64, 16, 16]         128      262,144\n",
      "6_model.layer1.0.ReLU_relu                                     -    [4, 64, 16, 16]           0            0\n",
      "7_model.layer1.0.Conv2d_conv2                     [64, 64, 3, 3]    [4, 64, 16, 16]      36,864   37,748,736\n",
      "8_model.layer1.0.BatchNorm2d_bn2                            [64]    [4, 64, 16, 16]         128      262,144\n",
      "9_model.layer1.0.ReLU_relu                                     -    [4, 64, 16, 16]           0            0\n",
      "10_model.layer1.0.Conv2d_conv3                   [64, 256, 1, 1]   [4, 256, 16, 16]      16,384   16,777,216\n",
      "11_model.layer1.0.BatchNorm2d_bn3                          [256]   [4, 256, 16, 16]         512    1,048,576\n",
      "12_model.layer1.0.downsample.Conv2d_0            [64, 256, 1, 1]   [4, 256, 16, 16]      16,384   16,777,216\n",
      "13_model.layer1.0.downsample.BatchNorm2d_1                 [256]   [4, 256, 16, 16]         512    1,048,576\n",
      "14_model.layer1.0.ReLU_relu                                    -   [4, 256, 16, 16]           0            0\n",
      "15_model.layer1.1.Conv2d_conv1                   [256, 64, 1, 1]    [4, 64, 16, 16]      16,384   16,777,216\n",
      "16_model.layer1.1.BatchNorm2d_bn1                           [64]    [4, 64, 16, 16]         128      262,144\n",
      "17_model.layer1.1.ReLU_relu                                    -    [4, 64, 16, 16]           0            0\n",
      "18_model.layer1.1.Conv2d_conv2                    [64, 64, 3, 3]    [4, 64, 16, 16]      36,864   37,748,736\n",
      "19_model.layer1.1.BatchNorm2d_bn2                           [64]    [4, 64, 16, 16]         128      262,144\n",
      "20_model.layer1.1.ReLU_relu                                    -    [4, 64, 16, 16]           0            0\n",
      "21_model.layer1.1.Conv2d_conv3                   [64, 256, 1, 1]   [4, 256, 16, 16]      16,384   16,777,216\n",
      "22_model.layer1.1.BatchNorm2d_bn3                          [256]   [4, 256, 16, 16]         512    1,048,576\n",
      "23_model.layer1.1.ReLU_relu                                    -   [4, 256, 16, 16]           0            0\n",
      "24_model.layer1.2.Conv2d_conv1                   [256, 64, 1, 1]    [4, 64, 16, 16]      16,384   16,777,216\n",
      "25_model.layer1.2.BatchNorm2d_bn1                           [64]    [4, 64, 16, 16]         128      262,144\n",
      "26_model.layer1.2.ReLU_relu                                    -    [4, 64, 16, 16]           0            0\n",
      "27_model.layer1.2.Conv2d_conv2                    [64, 64, 3, 3]    [4, 64, 16, 16]      36,864   37,748,736\n",
      "28_model.layer1.2.BatchNorm2d_bn2                           [64]    [4, 64, 16, 16]         128      262,144\n",
      "29_model.layer1.2.ReLU_relu                                    -    [4, 64, 16, 16]           0            0\n",
      "30_model.layer1.2.Conv2d_conv3                   [64, 256, 1, 1]   [4, 256, 16, 16]      16,384   16,777,216\n",
      "31_model.layer1.2.BatchNorm2d_bn3                          [256]   [4, 256, 16, 16]         512    1,048,576\n",
      "32_model.layer1.2.ReLU_relu                                    -   [4, 256, 16, 16]           0            0\n",
      "33_model.layer2.0.Conv2d_conv1                  [256, 128, 1, 1]   [4, 128, 16, 16]      32,768   33,554,432\n",
      "34_model.layer2.0.BatchNorm2d_bn1                          [128]   [4, 128, 16, 16]         256      524,288\n",
      "35_model.layer2.0.ReLU_relu                                    -   [4, 128, 16, 16]           0            0\n",
      "36_model.layer2.0.Conv2d_conv2                  [128, 128, 3, 3]     [4, 128, 8, 8]     147,456   37,748,736\n",
      "37_model.layer2.0.BatchNorm2d_bn2                          [128]     [4, 128, 8, 8]         256      131,072\n",
      "38_model.layer2.0.ReLU_relu                                    -     [4, 128, 8, 8]           0            0\n",
      "39_model.layer2.0.Conv2d_conv3                  [128, 512, 1, 1]     [4, 512, 8, 8]      65,536   16,777,216\n",
      "40_model.layer2.0.BatchNorm2d_bn3                          [512]     [4, 512, 8, 8]       1,024      524,288\n",
      "41_model.layer2.0.downsample.Conv2d_0           [256, 512, 1, 1]     [4, 512, 8, 8]     131,072   33,554,432\n",
      "42_model.layer2.0.downsample.BatchNorm2d_1                 [512]     [4, 512, 8, 8]       1,024      524,288\n",
      "43_model.layer2.0.ReLU_relu                                    -     [4, 512, 8, 8]           0            0\n",
      "44_model.layer2.1.Conv2d_conv1                  [512, 128, 1, 1]     [4, 128, 8, 8]      65,536   16,777,216\n",
      "45_model.layer2.1.BatchNorm2d_bn1                          [128]     [4, 128, 8, 8]         256      131,072\n",
      "46_model.layer2.1.ReLU_relu                                    -     [4, 128, 8, 8]           0            0\n",
      "47_model.layer2.1.Conv2d_conv2                  [128, 128, 3, 3]     [4, 128, 8, 8]     147,456   37,748,736\n",
      "48_model.layer2.1.BatchNorm2d_bn2                          [128]     [4, 128, 8, 8]         256      131,072\n",
      "49_model.layer2.1.ReLU_relu                                    -     [4, 128, 8, 8]           0            0\n",
      "50_model.layer2.1.Conv2d_conv3                  [128, 512, 1, 1]     [4, 512, 8, 8]      65,536   16,777,216\n",
      "51_model.layer2.1.BatchNorm2d_bn3                          [512]     [4, 512, 8, 8]       1,024      524,288\n",
      "52_model.layer2.1.ReLU_relu                                    -     [4, 512, 8, 8]           0            0\n",
      "53_model.layer2.2.Conv2d_conv1                  [512, 128, 1, 1]     [4, 128, 8, 8]      65,536   16,777,216\n",
      "54_model.layer2.2.BatchNorm2d_bn1                          [128]     [4, 128, 8, 8]         256      131,072\n",
      "55_model.layer2.2.ReLU_relu                                    -     [4, 128, 8, 8]           0            0\n",
      "56_model.layer2.2.Conv2d_conv2                  [128, 128, 3, 3]     [4, 128, 8, 8]     147,456   37,748,736\n",
      "57_model.layer2.2.BatchNorm2d_bn2                          [128]     [4, 128, 8, 8]         256      131,072\n",
      "58_model.layer2.2.ReLU_relu                                    -     [4, 128, 8, 8]           0            0\n",
      "59_model.layer2.2.Conv2d_conv3                  [128, 512, 1, 1]     [4, 512, 8, 8]      65,536   16,777,216\n",
      "60_model.layer2.2.BatchNorm2d_bn3                          [512]     [4, 512, 8, 8]       1,024      524,288\n",
      "61_model.layer2.2.ReLU_relu                                    -     [4, 512, 8, 8]           0            0\n",
      "62_model.layer2.3.Conv2d_conv1                  [512, 128, 1, 1]     [4, 128, 8, 8]      65,536   16,777,216\n",
      "63_model.layer2.3.BatchNorm2d_bn1                          [128]     [4, 128, 8, 8]         256      131,072\n",
      "64_model.layer2.3.ReLU_relu                                    -     [4, 128, 8, 8]           0            0\n",
      "65_model.layer2.3.Conv2d_conv2                  [128, 128, 3, 3]     [4, 128, 8, 8]     147,456   37,748,736\n",
      "66_model.layer2.3.BatchNorm2d_bn2                          [128]     [4, 128, 8, 8]         256      131,072\n",
      "67_model.layer2.3.ReLU_relu                                    -     [4, 128, 8, 8]           0            0\n",
      "68_model.layer2.3.Conv2d_conv3                  [128, 512, 1, 1]     [4, 512, 8, 8]      65,536   16,777,216\n",
      "69_model.layer2.3.BatchNorm2d_bn3                          [512]     [4, 512, 8, 8]       1,024      524,288\n",
      "70_model.layer2.3.ReLU_relu                                    -     [4, 512, 8, 8]           0            0\n",
      "71_model.layer3.0.Conv2d_conv1                  [512, 256, 1, 1]     [4, 256, 8, 8]     131,072   33,554,432\n",
      "72_model.layer3.0.BatchNorm2d_bn1                          [256]     [4, 256, 8, 8]         512      262,144\n",
      "73_model.layer3.0.ReLU_relu                                    -     [4, 256, 8, 8]           0            0\n",
      "74_model.layer3.0.Conv2d_conv2                  [256, 256, 3, 3]     [4, 256, 4, 4]     589,824   37,748,736\n",
      "75_model.layer3.0.BatchNorm2d_bn2                          [256]     [4, 256, 4, 4]         512       65,536\n",
      "76_model.layer3.0.ReLU_relu                                    -     [4, 256, 4, 4]           0            0\n",
      "77_model.layer3.0.Conv2d_conv3                 [256, 1024, 1, 1]    [4, 1024, 4, 4]     262,144   16,777,216\n",
      "78_model.layer3.0.BatchNorm2d_bn3                         [1024]    [4, 1024, 4, 4]       2,048      262,144\n",
      "79_model.layer3.0.downsample.Conv2d_0          [512, 1024, 1, 1]    [4, 1024, 4, 4]     524,288   33,554,432\n",
      "80_model.layer3.0.downsample.BatchNorm2d_1                [1024]    [4, 1024, 4, 4]       2,048      262,144\n",
      "81_model.layer3.0.ReLU_relu                                    -    [4, 1024, 4, 4]           0            0\n",
      "82_model.layer3.1.Conv2d_conv1                 [1024, 256, 1, 1]     [4, 256, 4, 4]     262,144   16,777,216\n",
      "83_model.layer3.1.BatchNorm2d_bn1                          [256]     [4, 256, 4, 4]         512       65,536\n",
      "84_model.layer3.1.ReLU_relu                                    -     [4, 256, 4, 4]           0            0\n",
      "85_model.layer3.1.Conv2d_conv2                  [256, 256, 3, 3]     [4, 256, 4, 4]     589,824   37,748,736\n",
      "86_model.layer3.1.BatchNorm2d_bn2                          [256]     [4, 256, 4, 4]         512       65,536\n",
      "87_model.layer3.1.ReLU_relu                                    -     [4, 256, 4, 4]           0            0\n",
      "88_model.layer3.1.Conv2d_conv3                 [256, 1024, 1, 1]    [4, 1024, 4, 4]     262,144   16,777,216\n",
      "89_model.layer3.1.BatchNorm2d_bn3                         [1024]    [4, 1024, 4, 4]       2,048      262,144\n",
      "90_model.layer3.1.ReLU_relu                                    -    [4, 1024, 4, 4]           0            0\n",
      "91_model.layer3.2.Conv2d_conv1                 [1024, 256, 1, 1]     [4, 256, 4, 4]     262,144   16,777,216\n",
      "92_model.layer3.2.BatchNorm2d_bn1                          [256]     [4, 256, 4, 4]         512       65,536\n",
      "93_model.layer3.2.ReLU_relu                                    -     [4, 256, 4, 4]           0            0\n",
      "94_model.layer3.2.Conv2d_conv2                  [256, 256, 3, 3]     [4, 256, 4, 4]     589,824   37,748,736\n",
      "95_model.layer3.2.BatchNorm2d_bn2                          [256]     [4, 256, 4, 4]         512       65,536\n",
      "96_model.layer3.2.ReLU_relu                                    -     [4, 256, 4, 4]           0            0\n",
      "97_model.layer3.2.Conv2d_conv3                 [256, 1024, 1, 1]    [4, 1024, 4, 4]     262,144   16,777,216\n",
      "98_model.layer3.2.BatchNorm2d_bn3                         [1024]    [4, 1024, 4, 4]       2,048      262,144\n",
      "99_model.layer3.2.ReLU_relu                                    -    [4, 1024, 4, 4]           0            0\n",
      "100_model.layer3.3.Conv2d_conv1                [1024, 256, 1, 1]     [4, 256, 4, 4]     262,144   16,777,216\n",
      "101_model.layer3.3.BatchNorm2d_bn1                         [256]     [4, 256, 4, 4]         512       65,536\n",
      "102_model.layer3.3.ReLU_relu                                   -     [4, 256, 4, 4]           0            0\n",
      "103_model.layer3.3.Conv2d_conv2                 [256, 256, 3, 3]     [4, 256, 4, 4]     589,824   37,748,736\n",
      "104_model.layer3.3.BatchNorm2d_bn2                         [256]     [4, 256, 4, 4]         512       65,536\n",
      "105_model.layer3.3.ReLU_relu                                   -     [4, 256, 4, 4]           0            0\n",
      "106_model.layer3.3.Conv2d_conv3                [256, 1024, 1, 1]    [4, 1024, 4, 4]     262,144   16,777,216\n",
      "107_model.layer3.3.BatchNorm2d_bn3                        [1024]    [4, 1024, 4, 4]       2,048      262,144\n",
      "108_model.layer3.3.ReLU_relu                                   -    [4, 1024, 4, 4]           0            0\n",
      "109_model.layer3.4.Conv2d_conv1                [1024, 256, 1, 1]     [4, 256, 4, 4]     262,144   16,777,216\n",
      "110_model.layer3.4.BatchNorm2d_bn1                         [256]     [4, 256, 4, 4]         512       65,536\n",
      "111_model.layer3.4.ReLU_relu                                   -     [4, 256, 4, 4]           0            0\n",
      "112_model.layer3.4.Conv2d_conv2                 [256, 256, 3, 3]     [4, 256, 4, 4]     589,824   37,748,736\n",
      "113_model.layer3.4.BatchNorm2d_bn2                         [256]     [4, 256, 4, 4]         512       65,536\n",
      "114_model.layer3.4.ReLU_relu                                   -     [4, 256, 4, 4]           0            0\n",
      "115_model.layer3.4.Conv2d_conv3                [256, 1024, 1, 1]    [4, 1024, 4, 4]     262,144   16,777,216\n",
      "116_model.layer3.4.BatchNorm2d_bn3                        [1024]    [4, 1024, 4, 4]       2,048      262,144\n",
      "117_model.layer3.4.ReLU_relu                                   -    [4, 1024, 4, 4]           0            0\n",
      "118_model.layer3.5.Conv2d_conv1                [1024, 256, 1, 1]     [4, 256, 4, 4]     262,144   16,777,216\n",
      "119_model.layer3.5.BatchNorm2d_bn1                         [256]     [4, 256, 4, 4]         512       65,536\n",
      "120_model.layer3.5.ReLU_relu                                   -     [4, 256, 4, 4]           0            0\n",
      "121_model.layer3.5.Conv2d_conv2                 [256, 256, 3, 3]     [4, 256, 4, 4]     589,824   37,748,736\n",
      "122_model.layer3.5.BatchNorm2d_bn2                         [256]     [4, 256, 4, 4]         512       65,536\n",
      "123_model.layer3.5.ReLU_relu                                   -     [4, 256, 4, 4]           0            0\n",
      "124_model.layer3.5.Conv2d_conv3                [256, 1024, 1, 1]    [4, 1024, 4, 4]     262,144   16,777,216\n",
      "125_model.layer3.5.BatchNorm2d_bn3                        [1024]    [4, 1024, 4, 4]       2,048      262,144\n",
      "126_model.layer3.5.ReLU_relu                                   -    [4, 1024, 4, 4]           0            0\n",
      "127_model.layer4.0.Conv2d_conv1                [1024, 512, 1, 1]     [4, 512, 4, 4]     524,288   33,554,432\n",
      "128_model.layer4.0.BatchNorm2d_bn1                         [512]     [4, 512, 4, 4]       1,024      131,072\n",
      "129_model.layer4.0.ReLU_relu                                   -     [4, 512, 4, 4]           0            0\n",
      "130_model.layer4.0.Conv2d_conv2                 [512, 512, 3, 3]     [4, 512, 2, 2]   2,359,296   37,748,736\n",
      "131_model.layer4.0.BatchNorm2d_bn2                         [512]     [4, 512, 2, 2]       1,024       32,768\n",
      "132_model.layer4.0.ReLU_relu                                   -     [4, 512, 2, 2]           0            0\n",
      "133_model.layer4.0.Conv2d_conv3                [512, 2048, 1, 1]    [4, 2048, 2, 2]   1,048,576   16,777,216\n",
      "134_model.layer4.0.BatchNorm2d_bn3                        [2048]    [4, 2048, 2, 2]       4,096      131,072\n",
      "135_model.layer4.0.downsample.Conv2d_0        [1024, 2048, 1, 1]    [4, 2048, 2, 2]   2,097,152   33,554,432\n",
      "136_model.layer4.0.downsample.BatchNorm2d_1               [2048]    [4, 2048, 2, 2]       4,096      131,072\n",
      "137_model.layer4.0.ReLU_relu                                   -    [4, 2048, 2, 2]           0            0\n",
      "138_model.layer4.1.Conv2d_conv1                [2048, 512, 1, 1]     [4, 512, 2, 2]   1,048,576   16,777,216\n",
      "139_model.layer4.1.BatchNorm2d_bn1                         [512]     [4, 512, 2, 2]       1,024       32,768\n",
      "140_model.layer4.1.ReLU_relu                                   -     [4, 512, 2, 2]           0            0\n",
      "141_model.layer4.1.Conv2d_conv2                 [512, 512, 3, 3]     [4, 512, 2, 2]   2,359,296   37,748,736\n",
      "142_model.layer4.1.BatchNorm2d_bn2                         [512]     [4, 512, 2, 2]       1,024       32,768\n",
      "143_model.layer4.1.ReLU_relu                                   -     [4, 512, 2, 2]           0            0\n",
      "144_model.layer4.1.Conv2d_conv3                [512, 2048, 1, 1]    [4, 2048, 2, 2]   1,048,576   16,777,216\n",
      "145_model.layer4.1.BatchNorm2d_bn3                        [2048]    [4, 2048, 2, 2]       4,096      131,072\n",
      "146_model.layer4.1.ReLU_relu                                   -    [4, 2048, 2, 2]           0            0\n",
      "147_model.layer4.2.Conv2d_conv1                [2048, 512, 1, 1]     [4, 512, 2, 2]   1,048,576   16,777,216\n",
      "148_model.layer4.2.BatchNorm2d_bn1                         [512]     [4, 512, 2, 2]       1,024       32,768\n",
      "149_model.layer4.2.ReLU_relu                                   -     [4, 512, 2, 2]           0            0\n",
      "150_model.layer4.2.Conv2d_conv2                 [512, 512, 3, 3]     [4, 512, 2, 2]   2,359,296   37,748,736\n",
      "151_model.layer4.2.BatchNorm2d_bn2                         [512]     [4, 512, 2, 2]       1,024       32,768\n",
      "152_model.layer4.2.ReLU_relu                                   -     [4, 512, 2, 2]           0            0\n",
      "153_model.layer4.2.Conv2d_conv3                [512, 2048, 1, 1]    [4, 2048, 2, 2]   1,048,576   16,777,216\n",
      "154_model.layer4.2.BatchNorm2d_bn3                        [2048]    [4, 2048, 2, 2]       4,096      131,072\n",
      "155_model.layer4.2.ReLU_relu                                   -    [4, 2048, 2, 2]           0            0\n",
      "156_model.AdaptiveAvgPool2d_avgpool                            -    [4, 2048, 1, 1]           0       40,960\n",
      "157_model.Linear_fc                                   [2048, 10]            [4, 10]      20,490      163,800\n",
      "============================================================================================================\n",
      "Total params: 23,528,522\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 23,508,032\n",
      "Total FLOPs: 1,349,296,088 / 1.35 GFLOPs\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 79.88\n",
      "Params size (MB): 89.75\n",
      "Estimated Total Size (MB): 169.82\n",
      "============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "tu.get_model_summary(model, torch.randn(4, 3, 64, 64, device=DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "2IMxBgWrUxOt",
    "outputId": "2fb5b194-09cf-4445-86af-063bc32f6272"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7b6503b6679c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Убедитесь, что preds имеет размерность [batch_size, num_classes]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Вычисление потерь\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-18e5bcc11158>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epoch_acc = []\n",
    "train_epoch_losses = []\n",
    "valid_epoch_losses = []\n",
    "valid_epoch_acc = []\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    loss_batch = []\n",
    "    acc_batch  = []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        preds = model(images)  # Убедитесь, что preds имеет размерность [batch_size, num_classes]\n",
    "\n",
    "        # Вычисление потерь\n",
    "        loss = criterion(preds, labels.long())  # Убедитесь, что labels имеют правильный тип\n",
    "        loss_batch.append(loss.item())\n",
    "\n",
    "        # Вычисление точности\n",
    "        predicted = torch.argmax(preds, dim=1)  # Получаем индексы классов с максимальной вероятностью\n",
    "        accuracy = (predicted == labels).cpu().numpy().mean()  # Сравниваем предсказанные классы с метками\n",
    "        acc_batch.append(accuracy)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_epoch_losses.append(np.mean(loss_batch))\n",
    "    train_epoch_acc.append(np.mean(acc_batch))\n",
    "\n",
    "    model.eval()\n",
    "    loss_batch = []\n",
    "    acc_batch  = []\n",
    "    for images, labels in valid_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            preds = model(images)  # Убедитесь, что preds имеет размерность [batch_size, num_classes]\n",
    "\n",
    "        loss = criterion(preds, labels.long())  # Убедитесь, что labels имеют правильный тип\n",
    "        loss_batch.append(loss.item())\n",
    "\n",
    "        # Вычисление точности\n",
    "        predicted = torch.argmax(preds, dim=1)  # Получаем индексы классов\n",
    "        accuracy = (predicted == labels).cpu().numpy().mean()  # Сравниваем предсказанные классы с метками\n",
    "        acc_batch.append(accuracy)\n",
    "\n",
    "    valid_epoch_losses.append(np.mean(loss_batch))\n",
    "    valid_epoch_acc.append(np.mean(acc_batch))\n",
    "\n",
    "    print(f'Epoch: {epoch}  loss_train: {train_epoch_losses[-1]:.3f}, loss_valid: {valid_epoch_losses[-1]:.3f}')\n",
    "    print(f'\\t  metrics_train: {train_epoch_acc[-1]:.3f}, metrics_valid: {valid_epoch_acc[-1]:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "5r21_03h65jm",
    "outputId": "f76f15cf-1032-4b38-f01d-ef925f02fb4f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchvision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c7e6eef9e674>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m test_dataset = torchvision.datasets.ImageFolder(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m'/content/dataset/test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrnsfrms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    '/content/dataset/test',\n",
    "    transform=trnsfrms\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "73ec0c878552fcb71893c22b7af2c9be9210ef33785c90eb804f443984ec4506"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
